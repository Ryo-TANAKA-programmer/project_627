---
  title: "STAT-627_PRJ"
format: pdf
editor: visual
---

\# Hey Bright!! I got your message!
=======
# Please **git pull** first before you edit the file!

# Hey Bright!! I got your message!
>>>>>>> c23e26e (adding uncommited changes)


```{r}
library(dplyr)
library(tidyverse)
#library(leaps)
#library(rms)
#library(dplyr)
#library(MASS)
#library(glmnet)
#library(caret)
#library(boot)
#library(car)
#library(olsrr)
```

# data preparation

```{r}

setwd(getwd()) # setting working directory for users

diabetes_data <- read_csv("Dataset_of_Diabetes.csv")
str(diabetes_data)

diabetes_data$BMI_Category <- cut(diabetes_data$BMI,
                                  breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
                                  labels = c("Underweight", "Normal", "Overweight", "Obese"))

```

#Data Cleaning

```{r}
## checking consistency of the levels in "Gender", "CLASS","BMI_Category"
unique_values <- lapply(diabetes_data[c("Gender", "CLASS","BMI_Category")], unique)
unique_values

## Fixing f = "F" and "N " = "N","Y "= "Y"
diabetes <- diabetes_data %>%
  mutate(across(c(3, 14), ~ recode(., "f" = "F", "N " = "N", "Y " = "Y")))

unique_values1 <- lapply(diabetes[c("Gender", "CLASS","BMI_Category")], unique)
unique_values1

# checking incomplete obs
diabetes <- diabetes %>%
  mutate(
    missing_count_SPS = rowSums(is.na(.[1:15])))

# Removing `P` in CLASS variable, ID and No.partition since we don't need them
diabetes <- diabetes[diabetes$CLASS != "P",]
diabetes <- diabetes[-c(1,2,16)]

# Bright will bring his thoughts on only-p-dataset Saturday!
p_only_diabetes <- diabetes %>% 
  filter(CLASS == "P")

# make CLASS to 0 and 1
diabetes <- diabetes %>%
  mutate(CLASS_BINARY = if_else(CLASS == "Y", 1, 0))
```

# Summary of the entire Dataset

```{r}
summary(diabetes)
```

```{r}
# summary of BMI
BMI_summary <- diabetes %>%
  group_by(Gender, BMI_Category) %>%
  summarise(Count = n(), .groups = 'drop')
BMI_summary
```

```{r}
# Making CLASS factor
diabetes <- diabetes %>% 
  mutate(CLASS = as.factor(CLASS))
is.factor(diabetes$CLASS)
```

```{r}
gg_base <- ggplot(data = diabetes) 

gg_base + geom_bar(mapping = aes(x = Gender,
                                 fill = BMI_Category),
                   position = "fill") +
  theme_bw()
```

```{r}
gg_base + geom_bar(mapping = aes(x = Gender,
                                 fill = CLASS),
                   position = "fill") +
  theme_bw()
```

```{r}
par(mfrow = c(5, 2))
diabetes_numeric_df <- diabetes[-c(1,12,13,14)]
for (col in colnames(diabetes_numeric_df)) {
  hist(diabetes_numeric_df[[col]], 
       main = col, 
       xlab = "")
}
```

```{r}
cor(diabetes_numeric_df)
```

-   Cr(Creatinine ratio) and Urea are categorized as highly correlated, therefore, we may want to deal with these variables. It is not surprising to see LDL and Cholesterole are also moderaly correlated.

```{r}
pairs(diabetes_numeric_df)
```

```{r}
diabetes$Gender <- as.factor(diabetes$Gender)
is.factor(diabetes$Gender)
full_reg <- glm(CLASS ~ .,
                family = "binomial",
                data = diabetes)
summary(full_reg) 
```

```{r}
plot(full_reg)
```

```{r}
# Removing non-significant variables

reduced_dia_reg <- glm(CLASS ~ Gender + HbA1c +
                         Chol + TG,
                       data = diabetes,
                       family = "binomial")
summary(reduced_dia_reg)

summary_reduced_reg <- summary(reduced_dia_reg)

```

```{r}
anova(full_reg,
      reduced_dia_reg)
```

```{r}
names(summary_reduced_reg)
```
## KNN

```{r}
library(class)
library(caret) 

set.seed(123)  
index <- createDataPartition(diabetes_data$CLASS, p = 0.5, list = FALSE)
train <- diabetes_data[index,]
test <- diabetes_data[-index,]

trainX <- scale(train[, c(4:11)])  
testX <- scale(test[, c(4:11)], center = attr(trainX, "scaled:center"), scale = attr(trainX, "scaled:scale"))
trainY <- train$CLASS
testY <- test$CLASS

k <- 5
pred <- knn(train = trainX, test = testX, cl = trainY, k = k)

# Evaluate the model
confMat <- table(Predicted = pred, Actual = testY)
print(confMat)
accuracy <- sum(diag(confMat)) / sum(confMat)
print(paste("Accuracy:", accuracy))
```

```{r}
library(class)
library(pROC)

auc_values <- numeric()  # To store AUC values
k_values <- 1:20  # Range of k values to test

for(k in k_values) {
  predicted_labels <- knn(train = trainX, test = testX, cl = trainY, k = k, prob = TRUE)
  prob <- attr(predicted_labels, "prob")
  prob_positive <- ifelse(predicted_labels == "P", prob, 1 - prob)
  roc_obj <- roc(testY, prob_positive, levels = c("N", "P"))
  auc_values[k] <- auc(roc_obj)
}

# Plot AUC values to see how they change with different k values
plot(k_values, auc_values, type = "b", xlab = "k", ylab = "AUC",
     main = "AUC vs. k for KNN")

# Find the k with the highest AUC
optimal_k <- which.max(auc_values)
cat("Optimal value of k:", optimal_k, "\nHighest AUC:", auc_values[optimal_k])
```

```{r}

set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(diabetes), replace=TRUE, prob=c(0.5, 0.5))
train_data <- diabetes[sample, ]
test_data <- diabetes[-sample, ]
x_train <- model.matrix(CLASS ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + HDL + LDL + VLDL + BMI + BMI_Category, data = train_data)[,-1] 
y_train <- train_data$CLASS
x_test <- model.matrix(CLASS ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + HDL + LDL + VLDL + BMI + BMI_Category, data = test_data)[,-1]
y_test <- test_data$CLASS

err_class <- rep(1:20)
tpr <- rep(1:20)
fpr <- rep(1:20)
# run the loop
for (k in 1:20) {
  Yhat <- knn(x_train, x_test, y_train, k = k) 
  err_class[k] <- mean(Yhat != y_test) # The prediction is not correct
  tpr[k] <- sum(Yhat == 1 & y_test == 1) / sum(y_test == 1) # TP/P
  fpr[k] <- sum(Yhat == 1 & y_test == 0) / sum(y_test == 0) # FP/N
}

ggplot(tibble(err_class, k = 1:20), aes(x = k, y = err_class)) +
  geom_line()
```

```{r}
which.min(err_class) # gives the k
```

```{r}
err_class[which.min(err_class)] # Probability of a Mis-classification 
```

```{r}
1 - err_class[which.min(err_class)] # Probability of a Correct Classification
```

```{r}
# calculate the accuracy for the best k
Yhat <-  knn(x_train, x_test, y_train, k = which.min(err_class)) 
table(y_test, Yhat)
```

```{r}
# Accuracy
(table(y_test, Yhat)[1, 1] + table(y_test, Yhat)[2, 2])/((1-0.5)*nrow(diabetes_data))
```

```{r}
Yhat <-  knn(x_train,x_test, y_train, k = 20) 
table(y_test, Yhat) # the Confusion Matrix
```

```{r}
# Accuracy
(table(y_test, Yhat)[1, 1] + table(y_test, Yhat)[2, 2])/(.5*nrow(diabetes_data))
```

```{r}
Yhat <-  knn(x_train, x_test, y_train, k = which.min(err_class)) 
table(y_test, Yhat) # the Confusion Matrix
```

```{r}
ggplot(tibble(tpr, fpr), aes(x = fpr, y = tpr)) +
  geom_line() +
  geom_abline(color = "red", lty = 3) +
  ylim(0, 1) + xlim(0, 1) +
  geom_hline(yintercept = mean(as.numeric(diabetes_data$CLASS)-1), color = "green", lty = 2)
```
## AIC

```{r}
AIC(reduced_dia_reg)
AIC(full_reg)
```

```{r}

```

```{r}
subreg_reduced <- regsubsets(CLASS ~ Gender + HbA1c + Chol + TG, 
                             data = diabetes, 
                             method = "exhaustive")
summary_subreg_reduced <- summary(subreg_reduced)
summary_subreg_reduced$cp
summary_subreg_reduced$adjr2
summary_subreg_reduced$bic
```

## STEP WISE

```{r}
fit.small <- glm(CLASS_BINARY~ 1,
                 family = "binomial",
                data = diabetes)

full_reg_BINARY <- glm(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI + BMI_Category,
                       family = "binomial",
                       data = diabetes)   # initial model

fit.step.15p <- step(full_reg_BINARY,
                     scope = list(lower=fit.small,
                                  upper=full_reg_BINARY),
                     direction = "both",
test = "F")


# last step has the best AIC which the best model is 
#Gender
#HbA1c
#Chol (Cholesterol)
#TG (Triglycerides)
#BMI (Body Mass Index)
#BMI_Category                             with response variable CLASS_BINARY
```

## CI

```{r}
model_matrix <- model.matrix(full_reg, data = diabetes)[,-1]
standardized_model_matrix <- scale(model_matrix)
svd_results <- svd(standardized_model_matrix)

eigenvalues <- svd_results$d^2
condition_index <- sqrt(max(eigenvalues) / eigenvalues)


column_names <- colnames(model_matrix)

ci_with_names <- data.frame(Variable = column_names, Condition_Index = condition_index)

print(ci_with_names)

# Low Condition Index (< 30) all of our predictors are fall within 30, unlikely to have multicollinearity.
```

## VIF

```{r}
vif_values <- vif(full_reg)

vif_values

# BMI category has multicollinearity issue, but i think its fine cause they are all from BMI.
# For the predictors with VIF values below 5, they are generally not concern of multicollinearity.


```

## Ridge and Lasso

```{r}
library(caret)
set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(diabetes), replace=TRUE, prob=c(0.5, 0.5))
train_data <- diabetes[sample, ]
test_data <- diabetes[!sample, ]

# Create Design Matrices
x_train <- model.matrix(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                          HDL + LDL + VLDL + BMI + BMI_Category, data = train_data)[,-1] 
y_train <- train_data$CLASS_BINARY

x_test <- model.matrix(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI + BMI_Category, data = test_data)[,-1] 
y_test <- test_data$CLASS_BINARY

# Ridge Regression 

cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, family = "binomial")
opt_lambda_ridge <- cv_ridge$lambda.min
ridge_model <- glmnet(x_train, y_train, alpha = 0, lambda = opt_lambda_ridge, family = "binomial")


# Lasso Regression 

cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
opt_lambda_lasso <- cv_lasso$lambda.min
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = opt_lambda_lasso, family = "binomial")

```

```{r}
# Evaluate Models


# Predictions on the testing set
predictions_ridge <- predict(ridge_model, s = opt_lambda_ridge, newx = x_test, type = "response")
predictions_lasso <- predict(lasso_model, s = opt_lambda_lasso, newx = x_test, type = "response")

# Convert predictions to binary class based on a threshold 0.5
predictions_ridge_binary <- ifelse(predictions_ridge > 0.5, 1, 0)
predictions_lasso_binary <- ifelse(predictions_lasso > 0.5, 1, 0)

# Calculate Accuracy 
accuracy_ridge <- mean(predictions_ridge_binary == y_test)
accuracy_lasso <- mean(predictions_lasso_binary == y_test)

# Print Accuracy for comparison
print(paste("Accuracy for Ridge Regression:", accuracy_ridge)) # 88% Accuracy rate
print(paste("Accuracy for Lasso Regression:", accuracy_lasso)) # 11% Accuracy rate
```
