---
  title: "STAT-627_PRJ"
format: pdf
editor: visual
---

\# Hey Bright!! I got your message!
=======
# Please **git pull** first before you edit the file!

# Hey Bright!! I got your message!
>>>>>>> c23e26e (adding uncommited changes)


```{r}
library(dplyr)
library(tidyverse)
library(leaps)
library(rms)
library(MASS)
library(glmnet)
library(caret)
library(boot)
library(car)
library(olsrr)
```

# data preparation

```{r}

setwd(getwd()) # setting working directory for users

diabetes_data <- read_csv("Dataset_of_Diabetes.csv")


diabetes_data$BMI_Category <- cut(diabetes_data$BMI,
                                  breaks = c(-Inf, 18.5, 24.9, 29.9, Inf),
                                  labels = c("Underweight", "Normal", "Overweight", "Obese"))
str(diabetes_data)

```

# Data Cleaning

```{r}
## checking consistency of the levels in "Gender", "CLASS","BMI_Category"
unique_values <- lapply(diabetes_data[c("Gender", "CLASS","BMI_Category")], unique)
unique_values

# ## Fixing f = "F" and "N " = "N","Y "= "Y"
# diabetes <- diabetes_data %>%
#   mutate(across(c(3, 14), ~ recode(., "f" = "F", "N " = "N", "Y " = "Y")))

diabetes <- diabetes_data

unique_values1 <- lapply(diabetes[c("Gender", "CLASS","BMI_Category")], unique)

# checking incomplete obs
diabetes <- diabetes %>%
  mutate(
    missing_count_SPS = rowSums(is.na(.[1:15])))

# Removing `P` in CLASS variable, ID and No.partition since we don't need them
diabetes <- diabetes[-c(1,2,16)]


# make CLASS to 0 and 1
diabetes <- diabetes %>%
  mutate(CLASS_BINARY = if_else(CLASS == "Y" | CLASS == "P", 1, 0))

diabetes$CLASS_BINARY <- as.factor(diabetes$CLASS_BINARY)
```

# Summary of the entire Dataset

```{r}
summary(diabetes)
```

```{r}
# summary of BMI
BMI_summary <- diabetes %>%
  group_by(Gender, BMI_Category) %>%
  summarise(Count = n(), .groups = 'drop')
BMI_summary
```

```{r}
# Making CLASS factor
diabetes <- diabetes %>% 
  mutate(CLASS = as.factor(CLASS))
is.factor(diabetes$CLASS)
```

```{r}
gg_base <- ggplot(data = diabetes) 

gg_base + geom_bar(mapping = aes(x = Gender,
                                 fill = BMI_Category),
                   position = "fill") +
  theme_bw()
```

```{r}
gg_base + geom_bar(mapping = aes(x = Gender,
                                 fill = CLASS_BINARY),
                   position = "fill") +
  theme_bw()
```

```{r}
par(mfrow = c(5, 2))
diabetes_numeric_df <- diabetes[-c(1,12,13,14)]
for (col in colnames(diabetes_numeric_df)) {
  hist(diabetes_numeric_df[[col]], 
       main = col, 
       xlab = "")
}
```

```{r}
cor(diabetes_numeric_df)
```

-   Cr(Creatinine ratio) and Urea are categorized as highly correlated, therefore, we may want to deal with these variables. It is not surprising to see LDL and Cholesterole are also moderaly correlated.

```{r}
pairs(diabetes_numeric_df)
```

```{r}
diabetes$Gender <- as.factor(diabetes$Gender)
is.factor(diabetes$Gender)
full_reg <- glm(CLASS ~ .,
                family = "binomial",
                data = diabetes)
summary(full_reg) 
```

```{r}
plot(full_reg)
```

```{r}
# Removing non-significant variables
reduced_dia_reg <- glm(CLASS ~ Gender + HbA1c +
                         Chol + TG,
                       data = diabetes,
                       family = "binomial")
summary(reduced_dia_reg)

summary_reduced_reg <- summary(reduced_dia_reg)
```

```{r}
anova(full_reg,
      reduced_dia_reg)
```

## KNN

```{r}
library(class)
library(caret) 

set.seed(123)  
index <- createDataPartition(diabetes_data$CLASS, p = 0.5, list = FALSE)
train <- diabetes_data[index,]
test <- diabetes_data[-index,]

trainX <- scale(train[, c(4:11)])  
testX <- scale(test[, c(4:11)], center = attr(trainX, "scaled:center"), scale = attr(trainX, "scaled:scale"))
trainY <- train$CLASS
testY <- test$CLASS

k <- 5
pred <- knn(train = trainX, test = testX, cl = trainY, k = k)

# Evaluate the model
confMat <- table(Predicted = pred, Actual = testY)
print(confMat)
accuracy <- sum(diag(confMat)) / sum(confMat)
print(paste("Accuracy:", accuracy))
```

```{r}
library(class)
library(pROC)

auc_values <- numeric()  # To store AUC values
k_values <- 1:20  # Range of k values to test

for(k in k_values) {
  predicted_labels <- knn(train = trainX, test = testX, cl = trainY, k = k, prob = TRUE)
  prob <- attr(predicted_labels, "prob")
  prob_positive <- ifelse(predicted_labels == "P", prob, 1 - prob)
  roc_obj <- roc(testY, prob_positive, levels = c("N", "P"))
  auc_values[k] <- auc(roc_obj)
}

# Plot AUC values to see how they change with different k values
plot(k_values, auc_values, type = "b", xlab = "k", ylab = "AUC",
     main = "AUC vs. k for KNN")

# Find the k with the highest AUC
optimal_k <- which.max(auc_values)
cat("Optimal value of k:", optimal_k, "\nHighest AUC:", auc_values[optimal_k])
```

```{r}

set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(diabetes), replace=TRUE, prob=c(0.5, 0.5))
train_data <- diabetes[sample, ]
test_data <- diabetes[-sample, ]
x_train <- model.matrix(CLASS ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + HDL + LDL + VLDL + BMI + BMI_Category, data = train_data)[,-1] 
y_train <- train_data$CLASS
x_test <- model.matrix(CLASS ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + HDL + LDL + VLDL + BMI + BMI_Category, data = test_data)[,-1]
y_test <- test_data$CLASS

err_class <- rep(1:20)
tpr <- rep(1:20)
fpr <- rep(1:20)
# run the loop
for (k in 1:20) {
  Yhat <- knn(x_train, x_test, y_train, k = k) 
  err_class[k] <- mean(Yhat != y_test) # The prediction is not correct
  tpr[k] <- sum(Yhat == 1 & y_test == 1) / sum(y_test == 1) # TP/P
  fpr[k] <- sum(Yhat == 1 & y_test == 0) / sum(y_test == 0) # FP/N
}

ggplot(tibble(err_class, k = 1:20), aes(x = k, y = err_class)) +
  geom_line()
```

```{r}
which.min(err_class) # gives the k
```

```{r}
err_class[which.min(err_class)] # Probability of a Mis-classification 
```

```{r}
1 - err_class[which.min(err_class)] # Probability of a Correct Classification
```

```{r}
# calculate the accuracy for the best k
Yhat <-  knn(x_train, x_test, y_train, k = which.min(err_class)) 
table(y_test, Yhat)
```

```{r}
# Accuracy
(table(y_test, Yhat)[1, 1] + table(y_test, Yhat)[2, 2])/((1-0.5)*nrow(diabetes_data))
```

```{r}
Yhat <-  knn(x_train,x_test, y_train, k = 20) 
table(y_test, Yhat) # the Confusion Matrix
```

```{r}
# Accuracy
(table(y_test, Yhat)[1, 1] + table(y_test, Yhat)[2, 2])/(.5*nrow(diabetes_data))
```

```{r}
Yhat <-  knn(x_train, x_test, y_train, k = which.min(err_class)) 
table(y_test, Yhat) # the Confusion Matrix
```

```{r}
ggplot(tibble(tpr, fpr), aes(x = fpr, y = tpr)) +
  geom_line() +
  geom_abline(color = "red", lty = 3) +
  ylim(0, 1) + xlim(0, 1) +
  geom_hline(yintercept = mean(as.numeric(diabetes_data$CLASS)-1), color = "green", lty = 2)
```

## STEP WISE

```{r}
fit.small <- glm(CLASS_BINARY~ 1,
                 family = "binomial",
                data = diabetes)

full_reg_BINARY <- glm(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI + BMI_Category,
                       family = "binomial",
                       data = diabetes)   # initial model

fit.step.15p <- step(full_reg_BINARY,
                     scope = list(lower=fit.small,
                                  upper=full_reg_BINARY),
                     direction = "both",
test = "F")
summary(fit.step.15p)


# last step has the best AIC which the best model is 
#Gender
#HbA1c
#Chol (Cholesterol)
#TG (Triglycerides)
#BMI (Body Mass Index)
#BMI_Category                             with response variable CLASS_BINARY
```

## CI

```{r}
model_matrix <- model.matrix(full_reg, data = diabetes)[,-1]
standardized_model_matrix <- scale(model_matrix)
svd_results <- svd(standardized_model_matrix)

eigenvalues <- svd_results$d^2
condition_index <- sqrt(max(eigenvalues) / eigenvalues)


column_names <- colnames(model_matrix)

ci_with_names <- data.frame(Variable = column_names, Condition_Index = condition_index)

print(ci_with_names)

# Low Condition Index (< 30) all of our predictors are fall within 30, unlikely to have multicollinearity.
```

## VIF

```{r}
vif_values <- vif(full_reg)

vif_values

# BMI category has multicollinearity issue, but i think its fine cause they are all from BMI.
# For the predictors with VIF values below 5, they are generally not concern of multicollinearity.


```

## Ridge and Lasso

```{r}
library(caret)
set.seed(123)
sample <- sample(c(TRUE, FALSE), nrow(diabetes), replace=TRUE, prob=c(0.5, 0.5))
train_data <- diabetes[sample, ]
test_data <- diabetes[!sample, ]

# Create Design Matrices
x_train <- model.matrix(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                          HDL + LDL + VLDL + BMI + BMI_Category, data = train_data)[,-1] 
y_train <- train_data$CLASS_BINARY

x_test <- model.matrix(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI + BMI_Category, data = test_data)[,-1] 
y_test <- test_data$CLASS_BINARY

# Ridge Regression 

cv_ridge <- cv.glmnet(x_train, y_train, alpha = 0, family = "binomial")
opt_lambda_ridge <- cv_ridge$lambda.min
ridge_model <- glmnet(x_train, y_train, alpha = 0, lambda = opt_lambda_ridge, family = "binomial")


# Lasso Regression 

cv_lasso <- cv.glmnet(x_train, y_train, alpha = 1, family = "binomial")
opt_lambda_lasso <- cv_lasso$lambda.min
lasso_model <- glmnet(x_train, y_train, alpha = 1, lambda = opt_lambda_lasso, family = "binomial")

```

```{r}
# Evaluate Models


# Predictions on the testing set
predictions_ridge <- predict(ridge_model, s = opt_lambda_ridge, newx = x_test, type = "response")
predictions_lasso <- predict(lasso_model, s = opt_lambda_lasso, newx = x_test, type = "response")

# Convert predictions to binary class based on a threshold 0.5
predictions_ridge_binary <- ifelse(predictions_ridge > 0.5, 1, 0)
predictions_lasso_binary <- ifelse(predictions_lasso > 0.5, 1, 0)

# Calculate Accuracy 
accuracy_ridge <- mean(predictions_ridge_binary == y_test)
accuracy_lasso <- mean(predictions_lasso_binary == y_test)

# Print Accuracy for comparison
print(paste("Accuracy for Ridge Regression:", accuracy_ridge)) # 88% Accuracy rate
print(paste("Accuracy for Lasso Regression:", accuracy_lasso)) # 11% Accuracy rate
```


# Bright Work

- logistic regression
```{r}

full_reg_BINARY1 <- glm(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI ,
                       family = "binomial",
                       data = diabetes)   # initial model
summary(full_reg_BINARY1)

vif_values <- vif(full_reg_BINARY1)

vif_values

reg_full_model <- glm(CLASS_BINARY ~ Gender + AGE + Urea + Cr + HbA1c + Chol + TG + 
                         HDL + LDL + VLDL + BMI ,
                       family = "binomial",
                       data = diabetes)
reg_null_model <- glm(CLASS_BINARY ~ 1,family = "binomial", data = diabetes)

fit.step.11p <- step(full_reg_BINARY1,
                     scope = list(lower=reg_null_model,
                                  upper=full_reg_BINARY1),
                     direction = "both",
test = "F")
summary(fit.step.11p)
```

```{r}
library(GGally)
ggpairs(diabetes[,-c(2,3,4,8,9,10,12,13)])
```
```{r}
ggplot(diabetes, aes(BMI_Category,HbA1c, color = CLASS_BINARY)) +
  geom_jitter(size = .5)

ggplot(diabetes, aes(BMI_Category,Chol, color = CLASS_BINARY)) +
  geom_jitter(size = .5)

ggplot(diabetes, aes(BMI_Category,TG  , color = CLASS_BINARY)) +
  geom_jitter(size = .5)

ggplot(diabetes, aes(BMI_Category,Gender  , color = CLASS_BINARY)) +
  geom_jitter(size = .5)


```


-LDA
```{r}
set.seed(123)
n <- nrow(diabetes)
Z <- sample(n, n/2)
# 1st slipt
Data_training = diabetes[Z, ]
Data_testing = diabetes[-Z, ]
# 2nd split
Data_training2 = diabetes[Z, ]
Data_testing2 = diabetes[-Z, ]

# Using first set of the split
lda_out <- lda(CLASS_BINARY ~ Gender + HbA1c + Chol + TG + BMI,data = Data_training) # don't need CV = TRUE

Predicted.CLASS_lda  <-  predict(lda_out, data.frame(Data_testing))$class

table(Data_testing$CLASS_BINARY, Predicted.CLASS_lda)

# Prediction Correct Classification Rate
round(mean(Data_testing$CLASS_BINARY == Predicted.CLASS_lda), 3)

round(mean(Predicted.CLASS_lda == "1"), 3)

round(mean(Data_testing$CLASS_BINARY == "1"), 3)

# Using first set of the split
lda_out2 <- lda(CLASS_BINARY ~ Gender + HbA1c + Chol + TG + BMI,data = Data_training2) # don't need CV = TRUE

Predicted.CLASS_lda2  <-  predict(lda_out2, data.frame(Data_testing2))$class

table(Data_testing2$CLASS_BINARY, Predicted.CLASS_lda2)

# Prediction Correct Classification Rate
round(mean(Data_testing2$CLASS_BINARY == Predicted.CLASS_lda2), 3)

round(mean(Predicted.CLASS_lda2 == "1"), 3)

round(mean(Data_testing2$CLASS_BINARY == "1"), 3)




```

QDA

```{r}
qda_out <- qda(CLASS_BINARY ~ Gender + HbA1c + Chol + TG + BMI,data = Data_training) # don't need CV = TRUE

Predicted.CLASS_qda  <-  predict(qda_out, data.frame(Data_training))$class

table(Data_training$CLASS_BINARY, Predicted.CLASS_qda)

# Prediction Correct Classification Rate
qda_ccr <- round(mean(Data_testing$CLASS_BINARY == Predicted.CLASS_qda), 3)
qda_ccr

round(mean(Predicted.CLASS_qda == "1"), 3)

round(mean(Data_testing$CLASS_BINARY == "1"), 3)



```

- logistic classication
```{r}
lreg_fit <-  glm(CLASS_BINARY ~ Gender + HbA1c + Chol + TG + BMI, 
    family = "binomial", data = Data_training)
summary(lreg_fit)

lreg_fit2 <-  glm(CLASS_BINARY ~ Gender + HbA1c + Chol + TG + BMI, 
    family = "binomial", data = Data_training2)
summary(lreg_fit)



Predicted_probability <- predict(lreg_fit, data.frame(Data_testing),
                                 type = "response")
Predicted_probability2 <- predict(lreg_fit2, data.frame(Data_testing2),
                                 type = "response")
Predicted_diabetic = Predicted_probability > 0.5
Predicted_diabetic2 = Predicted_probability2 > 0.5

table(Data_testing$CLASS_BINARY, Predicted_diabetic)

table(Data_testing$CLASS_BINARY, Predicted_diabetic2)

# Prediction Correct Classification Rate
log_ccr <- mean(Data_testing$CLASS_BINARY == Predicted_diabetic)
log_ccr


log_ccr2 <- mean(Data_testing$CLASS_BINARY == Predicted_diabetic2)
log_ccr2




```
```{r}

Prob <- predict(lreg_fit, data.frame(Data_testing),
                                 type = "response")
threshold <- seq(0, 1, .01)
length(threshold)

head(threshold)

TPR <-  FPR <- err.rate <- rep(0, length(threshold))

for (i in seq_along(threshold)) {
Yhat <- rep(NA_character_, nrow(diabetes[Z,])) 
Yhat <-  ifelse(Prob >= threshold[[i]], "1", "0")

err.rate[i] <- mean(Yhat != diabetes[Z,]$CLASS_BINARY)
TPR[[i]] <- sum(Yhat == "yes" & diabetes[Z,]$CLASS_BINARY == "1") /
  sum(diabetes[Z,]$CLASS_BINARY == "1")
FPR[[i]] <- sum(Yhat == "1" & diabetes[Z,]$CLASS_BINARY == "0") /
  sum(diabetes[Z,]$CLASS_BINARY == "no")

}

ggplot(tibble(threshold, err.rate),
       aes(threshold, err.rate)) + 
  geom_point()

which.min(err.rate)

threshold[0]

min(err.rate)


```




# Apendix
```{r}
  
data_test<- diabetes%>%
  select(-c(Gender,BMI_Category))

# Assuming Clean_data is your dataframe and CLASS is the grouping variable

# Define the function to perform ANOVA and tidy results
perform_anova <- function(data, group_var, ...) {
  # Select only numeric columns for ANOVA
  numeric_cols <- sapply(data, is.numeric)
  numeric_data <- data[, numeric_cols]
  
  # Perform ANOVA for each numeric column
  anova_results <- lapply(numeric_data, function(column) {
    aov_result <- aov(column ~ get(group_var), data = data)
    tidy(aov_result)
  })
  
  # Combine ANOVA results into a single dataframe
  anova_df <- do.call(rbind, anova_results)
  
  # Add column indicating the variable name
  anova_df$variable <- rownames(anova_df)
  
  return(anova_df)
}

# Apply the function to your data
data_anova <- data_test  %>%
  do(perform_anova(data_test, "CLASS"))

# Group by CLASS and calculate mean for each numeric variable
means_by_class <- data_test %>%
  group_by(CLASS) %>%
  summarise_all(mean,na.rm = TRUE)

additional_values_df <- data.frame(
  CLASS = "pvalue",
  AGE = 6.405477e-55,
  Urea = 6.329202e-02,
  Cr = 4.956277e-01,
  HbA1c = 1.031427e-81,
  Chol = 6.955116e-07,
  TG = 4.386920e-08,
  HDL = 6.524445e-01,
  LDL = 7.348649e-01,
  VLDL = 3.810216e-03,
  BMI = 4.714323e-90
)

# Bind the data frames
means_by_class1 <- bind_rows(means_by_class, additional_values_df)

# View the updated means_by_class data frame
print(means_by_class1)

```

